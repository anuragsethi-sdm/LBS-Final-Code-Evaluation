{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Mask Detection - Prediction & Deployment\n",
    "This notebook demonstrates how to use the trained model for predictions and deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "from utils.helpers import preprocess_face, detect_mask_colors\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "try:\n",
    "    model = tf.keras.models.load_model('model/face_mask_model.h5')\n",
    "    print(\"Model loaded successfully!\")\n",
    "    model.summary()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    print(\"Please run the training notebook first to create the model.\")\n",
    "    model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load face detection cascade\n",
    "face_cascade = cv2.CascadeClassifier('model/haarcascade_frontalface_default.xml')\n",
    "if face_cascade.empty():\n",
    "    # Fallback to OpenCV's built-in cascade\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    print(\"Using OpenCV's built-in face cascade\")\n",
    "else:\n",
    "    print(\"Face cascade loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face Mask Detection Pipeline\n",
    "class FaceMaskDetector:\n",
    "    def __init__(self, model, face_cascade):\n",
    "        self.model = model\n",
    "        self.face_cascade = face_cascade\n",
    "        \n",
    "    def detect_faces(self, image):\n",
    "        \"\"\"Detect faces in the image\"\"\"\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        faces = self.face_cascade.detectMultiScale(\n",
    "            gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30)\n",
    "        )\n",
    "        return faces\n",
    "    \n",
    "    def predict_mask(self, face_region):\n",
    "        \"\"\"Predict if face has mask using the trained model\"\"\"\n",
    "        if self.model is None:\n",
    "            # Fallback to color-based detection\n",
    "            has_mask, confidence = detect_mask_colors(face_region)\n",
    "            return confidence if has_mask else 1 - confidence\n",
    "        \n",
    "        # Preprocess face for model\n",
    "        processed_face = preprocess_face(face_region)\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = self.model.predict(processed_face, verbose=0)\n",
    "        return prediction[0][0]\n",
    "    \n",
    "    def process_image(self, image_path):\n",
    "        \"\"\"Process an image and detect masks\"\"\"\n",
    "        # Load image\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            raise ValueError(f\"Could not load image: {image_path}\")\n",
    "        \n",
    "        # Detect faces\n",
    "        faces = self.detect_faces(image)\n",
    "        \n",
    "        results = []\n",
    "        for (x, y, w, h) in faces:\n",
    "            # Extract face region\n",
    "            face_region = image[y:y+h, x:x+w]\n",
    "            \n",
    "            # Predict mask\n",
    "            mask_prob = self.predict_mask(face_region)\n",
    "            \n",
    "            # Determine label and color\n",
    "            if mask_prob > 0.5:\n",
    "                label = \"Mask\"\n",
    "                confidence = mask_prob * 100\n",
    "                color = (0, 255, 0)  # Green\n",
    "            else:\n",
    "                label = \"No Mask\"\n",
    "                confidence = (1 - mask_prob) * 100\n",
    "                color = (0, 0, 255)  # Red\n",
    "            \n",
    "            results.append({\n",
    "                'bbox': (x, y, w, h),\n",
    "                'label': label,\n",
    "                'confidence': confidence,\n",
    "                'color': color,\n",
    "                'mask_probability': mask_prob\n",
    "            })\n",
    "        \n",
    "        return image, results\n",
    "    \n",
    "    def draw_results(self, image, results):\n",
    "        \"\"\"Draw bounding boxes and labels on image\"\"\"\n",
    "        result_image = image.copy()\n",
    "        \n",
    "        for result in results:\n",
    "            x, y, w, h = result['bbox']\n",
    "            label = result['label']\n",
    "            confidence = result['confidence']\n",
    "            color = result['color']\n",
    "            \n",
    "            # Draw bounding box\n",
    "            cv2.rectangle(result_image, (x, y), (x+w, y+h), color, 2)\n",
    "            \n",
    "            # Draw label\n",
    "            text = f\"{label}: {confidence:.1f}%\"\n",
    "            (text_width, text_height), baseline = cv2.getTextSize(\n",
    "                text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2\n",
    "            )\n",
    "            \n",
    "            # Background rectangle for text\n",
    "            cv2.rectangle(result_image, (x, y-text_height-10), \n",
    "                         (x+text_width, y), color, -1)\n",
    "            cv2.putText(result_image, text, (x, y-5), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "        \n",
    "        return result_image\n",
    "\n",
    "# Initialize detector\n",
    "detector = FaceMaskDetector(model, face_cascade)\n",
    "print(\"Face Mask Detector initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test images for demonstration\n",
    "def create_test_images():\n",
    "    \"\"\"Create sample test images\"\"\"\n",
    "    os.makedirs('test_images', exist_ok=True)\n",
    "    \n",
    "    # Create sample images with faces\n",
    "    for i in range(3):\n",
    "        # Create a face-like image\n",
    "        img = np.random.randint(100, 200, (300, 300, 3), dtype=np.uint8)\n",
    "        \n",
    "        # Add face features\n",
    "        # Face outline\n",
    "        cv2.ellipse(img, (150, 150), (80, 100), 0, 0, 360, (200, 180, 160), -1)\n",
    "        \n",
    "        # Eyes\n",
    "        cv2.circle(img, (120, 120), 15, (50, 50, 50), -1)\n",
    "        cv2.circle(img, (180, 120), 15, (50, 50, 50), -1)\n",
    "        cv2.circle(img, (120, 120), 8, (255, 255, 255), -1)\n",
    "        cv2.circle(img, (180, 120), 8, (255, 255, 255), -1)\n",
    "        \n",
    "        # Nose\n",
    "        cv2.circle(img, (150, 150), 8, (180, 150, 130), -1)\n",
    "        \n",
    "        # Mouth area\n",
    "        cv2.ellipse(img, (150, 180), (20, 10), 0, 0, 180, (150, 100, 100), -1)\n",
    "        \n",
    "        # Add mask to some images\n",
    "        if i % 2 == 0:  # Add mask to even numbered images\n",
    "            mask_color = [(255, 255, 255), (100, 150, 255), (50, 50, 50)][i]\n",
    "            cv2.rectangle(img, (100, 160), (200, 200), mask_color, -1)\n",
    "            # Add mask straps\n",
    "            cv2.line(img, (100, 170), (80, 140), mask_color, 3)\n",
    "            cv2.line(img, (200, 170), (220, 140), mask_color, 3)\n",
    "        \n",
    "        # Save image\n",
    "        filename = f'test_images/test_face_{i+1}.jpg'\n",
    "        cv2.imwrite(filename, img)\n",
    "        print(f\"Created {filename}\")\n",
    "\n",
    "# Create test images\n",
    "create_test_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the detector on sample images\n",
    "test_image_paths = [\n",
    "    'test_images/test_face_1.jpg',\n",
    "    'test_images/test_face_2.jpg',\n",
    "    'test_images/test_face_3.jpg'\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "fig.suptitle('Face Mask Detection Results', fontsize=16)\n",
    "\n",
    "for i, image_path in enumerate(test_image_paths):\n",
    "    if os.path.exists(image_path):\n",
    "        # Process image\n",
    "        original_image, results = detector.process_image(image_path)\n",
    "        result_image = detector.draw_results(original_image, results)\n",
    "        \n",
    "        # Convert BGR to RGB for matplotlib\n",
    "        original_rgb = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "        result_rgb = cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Display original image\n",
    "        axes[0, i].imshow(original_rgb)\n",
    "        axes[0, i].set_title(f'Original Image {i+1}')\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # Display result image\n",
    "        axes[1, i].imshow(result_rgb)\n",
    "        \n",
    "        # Create title with detection results\n",
    "        if results:\n",
    "            result_text = ', '.join([f\"{r['label']} ({r['confidence']:.1f}%)\" for r in results])\n",
    "            axes[1, i].set_title(f'Results: {result_text}')\n",
    "        else:\n",
    "            axes[1, i].set_title('No faces detected')\n",
    "        \n",
    "        axes[1, i].axis('off')\n",
    "        \n",
    "        # Print detailed results\n",
    "        print(f\"\\nImage {i+1} Results:\")\n",
    "        print(f\"Faces detected: {len(results)}\")\n",
    "        for j, result in enumerate(results):\n",
    "            print(f\"  Face {j+1}: {result['label']} (Confidence: {result['confidence']:.1f}%, Mask Prob: {result['mask_probability']:.3f})\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-time webcam detection (optional)\n",
    "def run_webcam_detection():\n",
    "    \"\"\"Run real-time face mask detection using webcam\"\"\"\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam\")\n",
    "        return\n",
    "    \n",
    "    print(\"Starting webcam detection. Press 'q' to quit.\")\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Detect faces\n",
    "        faces = detector.detect_faces(frame)\n",
    "        \n",
    "        # Process each face\n",
    "        for (x, y, w, h) in faces:\n",
    "            face_region = frame[y:y+h, x:x+w]\n",
    "            mask_prob = detector.predict_mask(face_region)\n",
    "            \n",
    "            # Determine label and color\n",
    "            if mask_prob > 0.5:\n",
    "                label = \"Mask\"\n",
    "                confidence = mask_prob * 100\n",
    "                color = (0, 255, 0)\n",
    "            else:\n",
    "                label = \"No Mask\"\n",
    "                confidence = (1 - mask_prob) * 100\n",
    "                color = (0, 0, 255)\n",
    "            \n",
    "            # Draw bounding box and label\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "            text = f\"{label}: {confidence:.1f}%\"\n",
    "            cv2.putText(frame, text, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "        \n",
    "        # Display frame\n",
    "        cv2.imshow('Face Mask Detection', frame)\n",
    "        \n",
    "        # Check for quit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Webcam detection stopped.\")\n",
    "\n",
    "# Uncomment the line below to run webcam detection\n",
    "# run_webcam_detection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model deployment preparation\n",
    "def prepare_for_deployment():\n",
    "    \"\"\"Prepare model for deployment\"\"\"\n",
    "    print(\"Preparing model for deployment...\")\n",
    "    \n",
    "    # Save model in different formats\n",
    "    if model is not None:\n",
    "        # TensorFlow SavedModel format (recommended for deployment)\n",
    "        model.save('model/face_mask_model_deployment', save_format='tf')\n",
    "        print(\"✓ Saved in TensorFlow SavedModel format\")\n",
    "        \n",
    "        # TensorFlow Lite format (for mobile deployment)\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "        tflite_model = converter.convert()\n",
    "        \n",
    "        with open('model/face_mask_model.tflite', 'wb') as f:\n",
    "            f.write(tflite_model)\n",
    "        print(\"✓ Saved in TensorFlow Lite format\")\n",
    "        \n",
    "        # Model info\n",
    "        print(f\"\\nModel Information:\")\n",
    "        print(f\"Input shape: {model.input_shape}\")\n",
    "        print(f\"Output shape: {model.output_shape}\")\n",
    "        print(f\"Total parameters: {model.count_params():,}\")\n",
    "        \n",
    "        # Create deployment script\n",
    "        deployment_script = '''\n",
    "# Face Mask Detection Deployment Script\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "class FaceMaskPredictor:\n",
    "    def __init__(self, model_path):\n",
    "        self.model = tf.keras.models.load_model(model_path)\n",
    "        self.face_cascade = cv2.CascadeClassifier(\n",
    "            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
    "        )\n",
    "    \n",
    "    def predict(self, image_path):\n",
    "        image = cv2.imread(image_path)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        faces = self.face_cascade.detectMultiScale(gray, 1.1, 5)\n",
    "        \n",
    "        results = []\n",
    "        for (x, y, w, h) in faces:\n",
    "            face = image[y:y+h, x:x+w]\n",
    "            face_resized = cv2.resize(face, (150, 150)) / 255.0\n",
    "            face_batch = np.expand_dims(face_resized, axis=0)\n",
    "            \n",
    "            prediction = self.model.predict(face_batch)[0][0]\n",
    "            label = \"Mask\" if prediction > 0.5 else \"No Mask\"\n",
    "            confidence = prediction if prediction > 0.5 else 1 - prediction\n",
    "            \n",
    "            results.append({\n",
    "                'bbox': (x, y, w, h),\n",
    "                'label': label,\n",
    "                'confidence': confidence * 100\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Usage example:\n",
    "# predictor = FaceMaskPredictor('model/face_mask_model.h5')\n",
    "# results = predictor.predict('path/to/image.jpg')\n",
    "# print(results)\n",
    "'''\n",
    "        \n",
    "        with open('deploy_model.py', 'w') as f:\n",
    "            f.write(deployment_script)\n",
    "        print(\"✓ Created deployment script: deploy_model.py\")\n",
    "        \n",
    "    else:\n",
    "        print(\"❌ No model available for deployment. Please train the model first.\")\n",
    "\n",
    "# Prepare for deployment\n",
    "prepare_for_deployment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance benchmarking\n",
    "import time\n",
    "\n",
    "def benchmark_model():\n",
    "    \"\"\"Benchmark model performance\"\"\"\n",
    "    if model is None:\n",
    "        print(\"No model available for benchmarking\")\n",
    "        return\n",
    "    \n",
    "    print(\"Benchmarking model performance...\")\n",
    "    \n",
    "    # Create test batch\n",
    "    test_batch = np.random.random((32, 150, 150, 3)).astype(np.float32)\n",
    "    \n",
    "    # Warm up\n",
    "    for _ in range(5):\n",
    "        _ = model.predict(test_batch, verbose=0)\n",
    "    \n",
    "    # Benchmark\n",
    "    times = []\n",
    "    for _ in range(10):\n",
    "        start_time = time.time()\n",
    "        _ = model.predict(test_batch, verbose=0)\n",
    "        end_time = time.time()\n",
    "        times.append(end_time - start_time)\n",
    "    \n",
    "    avg_time = np.mean(times)\n",
    "    fps = 32 / avg_time  # Images per second\n",
    "    \n",
    "    print(f\"Average inference time: {avg_time:.4f} seconds\")\n",
    "    print(f\"Throughput: {fps:.2f} images/second\")\n",
    "    print(f\"Per image: {avg_time/32*1000:.2f} ms\")\n",
    "\n",
    "benchmark_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment Options\n",
    "\n",
    "### 1. Streamlit Web App\n",
    "```bash\n",
    "streamlit run streamlit_app.py\n",
    "```\n",
    "\n",
    "### 2. Flask API\n",
    "```python\n",
    "from flask import Flask, request, jsonify\n",
    "import tensorflow as tf\n",
    "\n",
    "app = Flask(__name__)\n",
    "model = tf.keras.models.load_model('model/face_mask_model.h5')\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    # Handle image upload and prediction\n",
    "    pass\n",
    "```\n",
    "\n",
    "### 3. Docker Deployment\n",
    "```dockerfile\n",
    "FROM tensorflow/tensorflow:2.13.0\n",
    "COPY . /app\n",
    "WORKDIR /app\n",
    "RUN pip install -r requirements.txt\n",
    "CMD [\"streamlit\", \"run\", \"streamlit_app.py\"]\n",
    "```\n",
    "\n",
    "### 4. Cloud Deployment\n",
    "- **Google Cloud AI Platform**\n",
    "- **AWS SageMaker**\n",
    "- **Azure ML**\n",
    "- **Heroku**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}